{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9f0e18c78d5a5c79e2b0ad520d520009b08a6bc4dca01046df0ae6eb4eaebae1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('creditcard_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = SMOTE().fit_sample(transactions_df.drop('Class', axis=1), transactions_df['Class'])\n",
    "res_transactions_df = pd.concat((X_res, y_res), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Time         V1        V2  ...       V28      Amount  Class\n",
       "0        33419.000000  -2.178201 -3.132187  ...  0.333476  937.750000      0\n",
       "1       151317.000000   2.064423  0.185575  ... -0.029665    1.980000      0\n",
       "2       132434.000000  -0.547505  0.798072  ... -0.015564   11.950000      0\n",
       "3        81787.000000  -0.945710  0.323579  ... -0.007543   24.980000      0\n",
       "4       125062.000000   1.898722 -0.321038  ... -0.059506  104.360000      0\n",
       "...               ...        ...       ...  ...       ...         ...    ...\n",
       "397995   11948.317802  -4.351654  3.467765  ...  0.763971   26.142719      1\n",
       "397996   41563.607129 -11.004002  6.254466  ... -0.608051  284.438582      1\n",
       "397997   81375.513504  -0.884634  1.791524  ...  0.177235    7.560990      1\n",
       "397998   29484.797678  -0.303537  3.448520  ...  0.164090    5.394058      1\n",
       "397999   12127.702035  -4.588430  3.303235  ...  0.711169   28.475433      1\n",
       "\n",
       "[398000 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33419.000000</td>\n      <td>-2.178201</td>\n      <td>-3.132187</td>\n      <td>1.315758</td>\n      <td>-0.129783</td>\n      <td>-2.736013</td>\n      <td>0.743459</td>\n      <td>-0.752718</td>\n      <td>-2.650826</td>\n      <td>-0.184284</td>\n      <td>-1.392226</td>\n      <td>-1.114831</td>\n      <td>0.253591</td>\n      <td>-0.428280</td>\n      <td>-0.724290</td>\n      <td>-2.442338</td>\n      <td>0.649252</td>\n      <td>1.192440</td>\n      <td>-1.782696</td>\n      <td>0.014677</td>\n      <td>2.534626</td>\n      <td>-0.828762</td>\n      <td>-0.219136</td>\n      <td>-1.004913</td>\n      <td>0.788588</td>\n      <td>1.061994</td>\n      <td>-0.319407</td>\n      <td>-0.132313</td>\n      <td>0.333476</td>\n      <td>937.750000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>151317.000000</td>\n      <td>2.064423</td>\n      <td>0.185575</td>\n      <td>-1.684612</td>\n      <td>0.411066</td>\n      <td>0.479555</td>\n      <td>-0.797963</td>\n      <td>0.205544</td>\n      <td>-0.240568</td>\n      <td>0.415454</td>\n      <td>-0.401418</td>\n      <td>-0.411296</td>\n      <td>0.439120</td>\n      <td>0.554022</td>\n      <td>-0.936324</td>\n      <td>0.196285</td>\n      <td>0.227611</td>\n      <td>0.510030</td>\n      <td>-0.465360</td>\n      <td>-0.031358</td>\n      <td>-0.130661</td>\n      <td>-0.351331</td>\n      <td>-0.876025</td>\n      <td>0.343288</td>\n      <td>0.522189</td>\n      <td>-0.259568</td>\n      <td>0.173623</td>\n      <td>-0.056280</td>\n      <td>-0.029665</td>\n      <td>1.980000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>132434.000000</td>\n      <td>-0.547505</td>\n      <td>0.798072</td>\n      <td>-0.719939</td>\n      <td>-1.129561</td>\n      <td>0.925708</td>\n      <td>0.763338</td>\n      <td>0.231338</td>\n      <td>0.799204</td>\n      <td>-0.277812</td>\n      <td>-0.348452</td>\n      <td>0.511676</td>\n      <td>-0.034514</td>\n      <td>-1.390963</td>\n      <td>1.067757</td>\n      <td>0.423194</td>\n      <td>-0.262177</td>\n      <td>-0.003822</td>\n      <td>-0.601821</td>\n      <td>-0.988247</td>\n      <td>-0.313966</td>\n      <td>0.366664</td>\n      <td>1.068933</td>\n      <td>-0.101523</td>\n      <td>-1.604148</td>\n      <td>-0.318277</td>\n      <td>0.838076</td>\n      <td>0.012324</td>\n      <td>-0.015564</td>\n      <td>11.950000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81787.000000</td>\n      <td>-0.945710</td>\n      <td>0.323579</td>\n      <td>0.595681</td>\n      <td>-1.288095</td>\n      <td>0.818906</td>\n      <td>-0.748491</td>\n      <td>0.890076</td>\n      <td>-0.130671</td>\n      <td>-0.471365</td>\n      <td>-0.389743</td>\n      <td>0.537702</td>\n      <td>0.137711</td>\n      <td>-0.555964</td>\n      <td>0.457870</td>\n      <td>-0.277456</td>\n      <td>0.662419</td>\n      <td>-0.951232</td>\n      <td>-0.103400</td>\n      <td>0.466225</td>\n      <td>-0.263767</td>\n      <td>-0.371528</td>\n      <td>-1.149510</td>\n      <td>0.217859</td>\n      <td>-0.507989</td>\n      <td>-0.026857</td>\n      <td>0.591496</td>\n      <td>-0.326179</td>\n      <td>-0.007543</td>\n      <td>24.980000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>125062.000000</td>\n      <td>1.898722</td>\n      <td>-0.321038</td>\n      <td>-1.771837</td>\n      <td>0.672408</td>\n      <td>0.115019</td>\n      <td>-1.267347</td>\n      <td>0.612810</td>\n      <td>-0.441070</td>\n      <td>0.450298</td>\n      <td>0.107004</td>\n      <td>-1.144233</td>\n      <td>-0.035721</td>\n      <td>-0.728277</td>\n      <td>0.565399</td>\n      <td>-0.368894</td>\n      <td>-0.494280</td>\n      <td>-0.107078</td>\n      <td>-0.658594</td>\n      <td>0.169095</td>\n      <td>-0.082106</td>\n      <td>0.015111</td>\n      <td>0.006269</td>\n      <td>-0.029094</td>\n      <td>-0.071333</td>\n      <td>0.179444</td>\n      <td>0.378225</td>\n      <td>-0.106042</td>\n      <td>-0.059506</td>\n      <td>104.360000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>397995</th>\n      <td>11948.317802</td>\n      <td>-4.351654</td>\n      <td>3.467765</td>\n      <td>-6.383989</td>\n      <td>6.373145</td>\n      <td>-2.118322</td>\n      <td>-1.720818</td>\n      <td>-4.967646</td>\n      <td>1.077450</td>\n      <td>-1.971173</td>\n      <td>-5.396462</td>\n      <td>6.142152</td>\n      <td>-12.084335</td>\n      <td>0.402296</td>\n      <td>-9.484561</td>\n      <td>0.497078</td>\n      <td>-7.281358</td>\n      <td>-10.736946</td>\n      <td>-4.295617</td>\n      <td>1.228121</td>\n      <td>0.038137</td>\n      <td>0.794857</td>\n      <td>0.177889</td>\n      <td>0.441887</td>\n      <td>-0.372011</td>\n      <td>-0.328381</td>\n      <td>0.071096</td>\n      <td>-0.832982</td>\n      <td>0.763971</td>\n      <td>26.142719</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397996</th>\n      <td>41563.607129</td>\n      <td>-11.004002</td>\n      <td>6.254466</td>\n      <td>-12.628058</td>\n      <td>7.162776</td>\n      <td>-9.575534</td>\n      <td>-1.707591</td>\n      <td>-11.731741</td>\n      <td>4.365579</td>\n      <td>-5.872360</td>\n      <td>-10.223044</td>\n      <td>4.539364</td>\n      <td>-9.046323</td>\n      <td>0.567731</td>\n      <td>-8.002257</td>\n      <td>0.678615</td>\n      <td>-8.992622</td>\n      <td>-15.337312</td>\n      <td>-7.066531</td>\n      <td>2.661543</td>\n      <td>-0.978365</td>\n      <td>1.777102</td>\n      <td>-0.562556</td>\n      <td>-1.393395</td>\n      <td>0.411258</td>\n      <td>-1.008284</td>\n      <td>-0.322712</td>\n      <td>-1.004433</td>\n      <td>-0.608051</td>\n      <td>284.438582</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397997</th>\n      <td>81375.513504</td>\n      <td>-0.884634</td>\n      <td>1.791524</td>\n      <td>-0.949333</td>\n      <td>3.854829</td>\n      <td>-1.543857</td>\n      <td>0.187519</td>\n      <td>-2.990668</td>\n      <td>1.343978</td>\n      <td>-2.295150</td>\n      <td>-1.891322</td>\n      <td>1.907629</td>\n      <td>-4.006053</td>\n      <td>-0.936073</td>\n      <td>-2.811108</td>\n      <td>0.795319</td>\n      <td>-2.352171</td>\n      <td>-6.431643</td>\n      <td>-0.829999</td>\n      <td>1.731353</td>\n      <td>0.370555</td>\n      <td>0.746115</td>\n      <td>0.549486</td>\n      <td>-0.035275</td>\n      <td>-0.567933</td>\n      <td>-0.526273</td>\n      <td>0.258701</td>\n      <td>0.507699</td>\n      <td>0.177235</td>\n      <td>7.560990</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397998</th>\n      <td>29484.797678</td>\n      <td>-0.303537</td>\n      <td>3.448520</td>\n      <td>-5.145009</td>\n      <td>4.790281</td>\n      <td>1.811835</td>\n      <td>-1.946380</td>\n      <td>0.667653</td>\n      <td>0.603985</td>\n      <td>-2.823833</td>\n      <td>-2.172252</td>\n      <td>3.811178</td>\n      <td>-1.668125</td>\n      <td>-1.192742</td>\n      <td>-6.994424</td>\n      <td>-0.290882</td>\n      <td>2.120081</td>\n      <td>5.405905</td>\n      <td>2.607732</td>\n      <td>-2.519857</td>\n      <td>0.051609</td>\n      <td>-0.016199</td>\n      <td>-0.338784</td>\n      <td>-0.559403</td>\n      <td>-0.419576</td>\n      <td>1.327724</td>\n      <td>0.481825</td>\n      <td>0.070503</td>\n      <td>0.164090</td>\n      <td>5.394058</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397999</th>\n      <td>12127.702035</td>\n      <td>-4.588430</td>\n      <td>3.303235</td>\n      <td>-6.126476</td>\n      <td>6.215802</td>\n      <td>-2.240519</td>\n      <td>-1.628718</td>\n      <td>-4.801014</td>\n      <td>1.074898</td>\n      <td>-1.590202</td>\n      <td>-4.641472</td>\n      <td>5.574131</td>\n      <td>-11.521696</td>\n      <td>0.511311</td>\n      <td>-8.534905</td>\n      <td>0.675376</td>\n      <td>-7.028030</td>\n      <td>-10.225526</td>\n      <td>-4.158977</td>\n      <td>1.489636</td>\n      <td>-0.097236</td>\n      <td>0.731554</td>\n      <td>0.260131</td>\n      <td>0.606618</td>\n      <td>-0.299903</td>\n      <td>-0.672566</td>\n      <td>0.009750</td>\n      <td>-1.119019</td>\n      <td>0.711169</td>\n      <td>28.475433</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>398000 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "res_transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['V' + str(i+1) for i in range(28) ]\n",
    "formula = 'Class ~ ' + ' + '.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   R-squared:                       0.689\n",
       "Model:                            OLS   Adj. R-squared:                  0.689\n",
       "Method:                 Least Squares   F-statistic:                 3.144e+04\n",
       "Date:                Mon, 26 Oct 2020   Prob (F-statistic):               0.00\n",
       "Time:                        11:41:42   Log-Likelihood:                -56671.\n",
       "No. Observations:              398000   AIC:                         1.134e+05\n",
       "Df Residuals:                  397971   BIC:                         1.137e+05\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1571      0.001    273.744      0.000       0.156       0.158\n",
       "V1            -0.0184      0.000    -77.404      0.000      -0.019      -0.018\n",
       "V2             0.0042      0.000     13.930      0.000       0.004       0.005\n",
       "V3            -0.0046      0.000    -16.025      0.000      -0.005      -0.004\n",
       "V4             0.0542      0.000    158.685      0.000       0.054       0.055\n",
       "V5             0.0024      0.000      7.298      0.000       0.002       0.003\n",
       "V6            -0.0132      0.000    -32.169      0.000      -0.014      -0.012\n",
       "V7             0.0292      0.000     89.909      0.000       0.029       0.030\n",
       "V8            -0.0172      0.000    -91.059      0.000      -0.018      -0.017\n",
       "V9             0.0084      0.000     18.867      0.000       0.008       0.009\n",
       "V10           -0.0214      0.000    -54.776      0.000      -0.022      -0.021\n",
       "V11            0.0019      0.000      3.945      0.000       0.001       0.003\n",
       "V12            0.0178      0.000     44.601      0.000       0.017       0.019\n",
       "V13           -0.0294      0.000    -62.015      0.000      -0.030      -0.029\n",
       "V14           -0.0616      0.000   -187.032      0.000      -0.062      -0.061\n",
       "V15            0.0013      0.001      2.438      0.015       0.000       0.002\n",
       "V16            0.0065      0.001     11.376      0.000       0.005       0.008\n",
       "V17           -0.0141      0.000    -38.124      0.000      -0.015      -0.013\n",
       "V18            0.0357      0.001     57.415      0.000       0.034       0.037\n",
       "V19            0.0151      0.001     27.500      0.000       0.014       0.016\n",
       "V20            0.0274      0.001     45.252      0.000       0.026       0.029\n",
       "V21            0.0170      0.000     48.630      0.000       0.016       0.018\n",
       "V22            0.0292      0.001     41.974      0.000       0.028       0.031\n",
       "V23           -0.0356      0.001    -68.858      0.000      -0.037      -0.035\n",
       "V24            0.0190      0.001     21.607      0.000       0.017       0.021\n",
       "V25           -0.0083      0.001     -9.676      0.000      -0.010      -0.007\n",
       "V26           -0.0682      0.001    -64.558      0.000      -0.070      -0.066\n",
       "V27            0.0038      0.001      6.106      0.000       0.003       0.005\n",
       "V28            0.0510      0.001     41.585      0.000       0.049       0.053\n",
       "==============================================================================\n",
       "Omnibus:                    25952.695   Durbin-Watson:                   1.378\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31527.973\n",
       "Skew:                           0.655   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.431   Cond. No.                         48.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ],
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>          <td>Class</td>      <th>  R-squared:         </th> <td>   0.689</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.689</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>3.144e+04</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 26 Oct 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n</tr>\n<tr>\n  <th>Time:</th>                 <td>11:41:42</td>     <th>  Log-Likelihood:    </th> <td> -56671.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>398000</td>      <th>  AIC:               </th> <td>1.134e+05</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>397971</td>      <th>  BIC:               </th> <td>1.137e+05</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th> <td>    0.1571</td> <td>    0.001</td> <td>  273.744</td> <td> 0.000</td> <td>    0.156</td> <td>    0.158</td>\n</tr>\n<tr>\n  <th>V1</th>        <td>   -0.0184</td> <td>    0.000</td> <td>  -77.404</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.018</td>\n</tr>\n<tr>\n  <th>V2</th>        <td>    0.0042</td> <td>    0.000</td> <td>   13.930</td> <td> 0.000</td> <td>    0.004</td> <td>    0.005</td>\n</tr>\n<tr>\n  <th>V3</th>        <td>   -0.0046</td> <td>    0.000</td> <td>  -16.025</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.004</td>\n</tr>\n<tr>\n  <th>V4</th>        <td>    0.0542</td> <td>    0.000</td> <td>  158.685</td> <td> 0.000</td> <td>    0.054</td> <td>    0.055</td>\n</tr>\n<tr>\n  <th>V5</th>        <td>    0.0024</td> <td>    0.000</td> <td>    7.298</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n</tr>\n<tr>\n  <th>V6</th>        <td>   -0.0132</td> <td>    0.000</td> <td>  -32.169</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.012</td>\n</tr>\n<tr>\n  <th>V7</th>        <td>    0.0292</td> <td>    0.000</td> <td>   89.909</td> <td> 0.000</td> <td>    0.029</td> <td>    0.030</td>\n</tr>\n<tr>\n  <th>V8</th>        <td>   -0.0172</td> <td>    0.000</td> <td>  -91.059</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.017</td>\n</tr>\n<tr>\n  <th>V9</th>        <td>    0.0084</td> <td>    0.000</td> <td>   18.867</td> <td> 0.000</td> <td>    0.008</td> <td>    0.009</td>\n</tr>\n<tr>\n  <th>V10</th>       <td>   -0.0214</td> <td>    0.000</td> <td>  -54.776</td> <td> 0.000</td> <td>   -0.022</td> <td>   -0.021</td>\n</tr>\n<tr>\n  <th>V11</th>       <td>    0.0019</td> <td>    0.000</td> <td>    3.945</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n</tr>\n<tr>\n  <th>V12</th>       <td>    0.0178</td> <td>    0.000</td> <td>   44.601</td> <td> 0.000</td> <td>    0.017</td> <td>    0.019</td>\n</tr>\n<tr>\n  <th>V13</th>       <td>   -0.0294</td> <td>    0.000</td> <td>  -62.015</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.029</td>\n</tr>\n<tr>\n  <th>V14</th>       <td>   -0.0616</td> <td>    0.000</td> <td> -187.032</td> <td> 0.000</td> <td>   -0.062</td> <td>   -0.061</td>\n</tr>\n<tr>\n  <th>V15</th>       <td>    0.0013</td> <td>    0.001</td> <td>    2.438</td> <td> 0.015</td> <td>    0.000</td> <td>    0.002</td>\n</tr>\n<tr>\n  <th>V16</th>       <td>    0.0065</td> <td>    0.001</td> <td>   11.376</td> <td> 0.000</td> <td>    0.005</td> <td>    0.008</td>\n</tr>\n<tr>\n  <th>V17</th>       <td>   -0.0141</td> <td>    0.000</td> <td>  -38.124</td> <td> 0.000</td> <td>   -0.015</td> <td>   -0.013</td>\n</tr>\n<tr>\n  <th>V18</th>       <td>    0.0357</td> <td>    0.001</td> <td>   57.415</td> <td> 0.000</td> <td>    0.034</td> <td>    0.037</td>\n</tr>\n<tr>\n  <th>V19</th>       <td>    0.0151</td> <td>    0.001</td> <td>   27.500</td> <td> 0.000</td> <td>    0.014</td> <td>    0.016</td>\n</tr>\n<tr>\n  <th>V20</th>       <td>    0.0274</td> <td>    0.001</td> <td>   45.252</td> <td> 0.000</td> <td>    0.026</td> <td>    0.029</td>\n</tr>\n<tr>\n  <th>V21</th>       <td>    0.0170</td> <td>    0.000</td> <td>   48.630</td> <td> 0.000</td> <td>    0.016</td> <td>    0.018</td>\n</tr>\n<tr>\n  <th>V22</th>       <td>    0.0292</td> <td>    0.001</td> <td>   41.974</td> <td> 0.000</td> <td>    0.028</td> <td>    0.031</td>\n</tr>\n<tr>\n  <th>V23</th>       <td>   -0.0356</td> <td>    0.001</td> <td>  -68.858</td> <td> 0.000</td> <td>   -0.037</td> <td>   -0.035</td>\n</tr>\n<tr>\n  <th>V24</th>       <td>    0.0190</td> <td>    0.001</td> <td>   21.607</td> <td> 0.000</td> <td>    0.017</td> <td>    0.021</td>\n</tr>\n<tr>\n  <th>V25</th>       <td>   -0.0083</td> <td>    0.001</td> <td>   -9.676</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.007</td>\n</tr>\n<tr>\n  <th>V26</th>       <td>   -0.0682</td> <td>    0.001</td> <td>  -64.558</td> <td> 0.000</td> <td>   -0.070</td> <td>   -0.066</td>\n</tr>\n<tr>\n  <th>V27</th>       <td>    0.0038</td> <td>    0.001</td> <td>    6.106</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n</tr>\n<tr>\n  <th>V28</th>       <td>    0.0510</td> <td>    0.001</td> <td>   41.585</td> <td> 0.000</td> <td>    0.049</td> <td>    0.053</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>25952.695</td> <th>  Durbin-Watson:     </th> <td>   1.378</td> \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>31527.973</td>\n</tr>\n<tr>\n  <th>Skew:</th>           <td> 0.655</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n</tr>\n<tr>\n  <th>Kurtosis:</th>       <td> 3.431</td>   <th>  Cond. No.          </th> <td>    48.5</td> \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "model = smf.ols(formula, res_transactions_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "V1 8.138722973828493\n",
      "V2 5.79956205882602\n",
      "V3 15.289135538439266\n",
      "V4 5.856811397096758\n",
      "V5 8.740343185579516\n",
      "V6 2.469816647478723\n",
      "V7 17.273547245976435\n",
      "V8 4.042552740362449\n",
      "V9 5.05244675227656\n",
      "V10 15.095596230906482\n",
      "V11 8.33026087103937\n",
      "V12 16.20875468562786\n",
      "V13 1.167443373171677\n",
      "V14 11.558536357306151\n",
      "V15 1.2209344735858745\n",
      "V16 18.23120327193029\n",
      "V17 22.502748644822955\n",
      "V18 10.307498243074432\n",
      "V19 2.0447617594012844\n",
      "V20 2.058687424469567\n",
      "V21 4.438290763891195\n",
      "V22 3.0650302212168556\n",
      "V23 1.51084689147749\n",
      "V24 1.1547244022923977\n",
      "V25 1.4093518283461808\n",
      "V26 1.1282578925689217\n",
      "V27 1.7840253553021213\n",
      "V28 1.3686928404871976\n",
      "['V3', 'V7', 'V10', 'V12', 'V14', 'V16', 'V17', 'V18']\n",
      "['V1', 'V2', 'V4', 'V5', 'V6', 'V8', 'V9', 'V11', 'V13', 'V15', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n"
     ]
    }
   ],
   "source": [
    "collinear_features = []\n",
    "for feature in features:\n",
    "    other_features = features.copy()\n",
    "    other_features.remove(feature)\n",
    "    feature_formula = feature + ' ~ ' + ' + '.join(other_features)\n",
    "    feature_model = smf.ols(feature_formula, res_transactions_df).fit()\n",
    "    VIF = 1/(1 - feature_model.rsquared)\n",
    "    if VIF >= 10:\n",
    "        collinear_features.append(feature)\n",
    "    print(feature, VIF)\n",
    "\n",
    "noncollinear_features = [feature for feature in features if feature not in collinear_features]\n",
    "print(collinear_features)\n",
    "print(noncollinear_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "def print_metrics(y_test, y_hat):\n",
    "    print('recall', recall_score(y_test, y_hat))\n",
    "    print('precision', precision_score(y_test, y_hat))\n",
    "    print('F1', f1_score(y_test, y_hat))\n",
    "X_train, y_train = res_transactions_df[noncollinear_features], res_transactions_df['Class']\n",
    "test_df = pd.read_csv('creditcard_test.csv')\n",
    "X_test, y_test = test_df[noncollinear_features], test_df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "recall 0.75\nprecision 0.7619047619047619\nF1 0.7559055118110236\n"
     ]
    }
   ],
   "source": [
    "y_hat = rfc.predict(test_df[noncollinear_features])\n",
    "print_metrics(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "recall 0.875\nprecision 0.03523120478137779\nF1 0.06773510734804959\n"
     ]
    }
   ],
   "source": [
    "y_hat = abc.predict(X_test)\n",
    "print_metrics(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}